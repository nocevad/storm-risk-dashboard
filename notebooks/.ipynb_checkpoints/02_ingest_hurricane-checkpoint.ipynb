{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607fe33e-27ac-4cee-abce-2cffb88c4c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "\n",
    "load_dotenv(r\"C:\\Projects\\storm_risk\\.env\")\n",
    "\n",
    "engine = create_engine(\n",
    "    \"mysql+mysqlconnector://\",\n",
    "    connect_args={\n",
    "        \"host\"    : os.getenv('MYSQL_HOST'),\n",
    "        \"user\"    : os.getenv('MYSQL_USER'),\n",
    "        \"password\": os.getenv('MYSQL_PASSWORD'),\n",
    "        \"database\": os.getenv('MYSQL_DATABASE')\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ Connected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0133601-8358-4070-9b71-bac381f00e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in file: 56722\n",
      "\n",
      "First 20 lines:\n",
      "\n",
      "AL011851,            UNNAMED,     14,\n",
      "18510625, 0000,  , HU, 28.0N,  94.8W,  80, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510625, 0600,  , HU, 28.0N,  95.4W,  80, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510625, 1200,  , HU, 28.0N,  96.0W,  80, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510625, 1800,  , HU, 28.1N,  96.5W,  80, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510625, 2100, L, HU, 28.2N,  96.8W,  80, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510626, 0000,  , HU, 28.2N,  97.0W,  70, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510626, 0600,  , TS, 28.3N,  97.6W,  60, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510626, 1200,  , TS, 28.4N,  98.3W,  60, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510626, 1800,  , TS, 28.6N,  98.9W,  50, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510627, 0000,  , TS, 29.0N,  99.4W,  50, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510627, 0600,  , TS, 29.5N,  99.8W,  40, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510627, 1200,  , TS, 30.0N, 100.0W,  40, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510627, 1800,  , TS, 30.5N, 100.1W,  40, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "18510628, 0000,  , TS, 31.0N, 100.2W,  40, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "AL021851,            UNNAMED,      1,\n",
      "18510705, 1200,  , HU, 22.2N,  97.6W,  80, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "AL031851,            UNNAMED,      1,\n",
      "18510710, 1200,  , TS, 12.0N,  60.0W,  50, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\n",
      "AL041851,            UNNAMED,     49,\n"
     ]
    }
   ],
   "source": [
    "# Download the raw HURDAT2 file from NOAA\n",
    "url = \"https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2023-051124.txt\"\n",
    "\n",
    "response = requests.get(url)\n",
    "raw_text = response.text\n",
    "\n",
    "# Split into lines\n",
    "lines = raw_text.strip().split('\\n')\n",
    "\n",
    "print(f\"Total lines in file: {len(lines)}\")\n",
    "print(f\"\\nFirst 20 lines:\\n\")\n",
    "for line in lines[:20]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50618d40-85fe-45d4-bd3e-794b82ae7da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total storm observations parsed: 54749\n",
      "Unique storms: 1973\n",
      "Date range: 1851-06-25 00:00:00 to 2023-10-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storm_id</th>\n",
       "      <th>storm_name</th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-94.8</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-95.4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25</td>\n",
       "      <td>28.1</td>\n",
       "      <td>-96.5</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-96.8</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-26</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-26</td>\n",
       "      <td>28.3</td>\n",
       "      <td>-97.6</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-26</td>\n",
       "      <td>28.4</td>\n",
       "      <td>-98.3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-26</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-98.9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-99.4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   storm_id storm_name       date  latitude  longitude  wind_speed\n",
       "0  AL011851    UNNAMED 1851-06-25      28.0      -94.8          80\n",
       "1  AL011851    UNNAMED 1851-06-25      28.0      -95.4          80\n",
       "2  AL011851    UNNAMED 1851-06-25      28.0      -96.0          80\n",
       "3  AL011851    UNNAMED 1851-06-25      28.1      -96.5          80\n",
       "4  AL011851    UNNAMED 1851-06-25      28.2      -96.8          80\n",
       "5  AL011851    UNNAMED 1851-06-26      28.2      -97.0          70\n",
       "6  AL011851    UNNAMED 1851-06-26      28.3      -97.6          60\n",
       "7  AL011851    UNNAMED 1851-06-26      28.4      -98.3          60\n",
       "8  AL011851    UNNAMED 1851-06-26      28.6      -98.9          50\n",
       "9  AL011851    UNNAMED 1851-06-27      29.0      -99.4          50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storms = []\n",
    "current_storm_id   = None\n",
    "current_storm_name = None\n",
    "\n",
    "for line in lines:\n",
    "    parts = [p.strip() for p in line.split(',')]\n",
    "    \n",
    "    # Header row has storm ID starting with AL, EP, or CP\n",
    "    if parts[0].startswith(('AL','EP','CP')):\n",
    "        current_storm_id   = parts[0]\n",
    "        current_storm_name = parts[1]\n",
    "    else:\n",
    "        # Data row\n",
    "        try:\n",
    "            date_str  = parts[0].strip()\n",
    "            time_str  = parts[1].strip().zfill(4)\n",
    "            \n",
    "            # Parse lat/lon\n",
    "            lat_str   = parts[4].strip()\n",
    "            lon_str   = parts[5].strip()\n",
    "            \n",
    "            lat = float(lat_str[:-1]) * (1 if lat_str[-1] == 'N' else -1)\n",
    "            lon = float(lon_str[:-1]) * (-1 if lon_str[-1] == 'W' else 1)\n",
    "            \n",
    "            wind_speed = int(parts[6].strip())\n",
    "            \n",
    "            # Skip missing wind speed\n",
    "            if wind_speed == -999:\n",
    "                continue\n",
    "                \n",
    "            storms.append({\n",
    "                'storm_id'  : current_storm_id,\n",
    "                'storm_name': current_storm_name,\n",
    "                'date'      : pd.to_datetime(date_str, format='%Y%m%d'),\n",
    "                'latitude'  : lat,\n",
    "                'longitude' : lon,\n",
    "                'wind_speed': wind_speed\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "hurdat = pd.DataFrame(storms)\n",
    "\n",
    "print(f\"Total storm observations parsed: {len(hurdat)}\")\n",
    "print(f\"Unique storms: {hurdat['storm_id'].nunique()}\")\n",
    "print(f\"Date range: {hurdat['date'].min()} to {hurdat['date'].max()}\")\n",
    "hurdat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b129714-a63f-4f6b-bffd-cb66ad3c9ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "County centroids loaded: 3221\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_code</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>32.508438</td>\n",
       "      <td>-86.658643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01009</td>\n",
       "      <td>33.950498</td>\n",
       "      <td>-86.634968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01017</td>\n",
       "      <td>32.892438</td>\n",
       "      <td>-85.264489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01021</td>\n",
       "      <td>32.840318</td>\n",
       "      <td>-86.697518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01033</td>\n",
       "      <td>34.712311</td>\n",
       "      <td>-87.873360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fips_code        lat        lon\n",
       "0     01001  32.508438 -86.658643\n",
       "1     01009  33.950498 -86.634968\n",
       "2     01017  32.892438 -85.264489\n",
       "3     01021  32.840318 -86.697518\n",
       "4     01033  34.712311 -87.873360"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull counties from MySQL with their FIPS codes\n",
    "counties = pd.read_sql(\"SELECT fips_code, state_name FROM counties\", engine)\n",
    "\n",
    "# We need lat/lon centroids for each county\n",
    "# Load from the Census GeoJSON which has this built in\n",
    "import requests\n",
    "\n",
    "geojson_url = \"https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json\"\n",
    "geojson = requests.get(geojson_url).json()\n",
    "\n",
    "# Extract centroid for each county from GeoJSON\n",
    "centroids = []\n",
    "for feature in geojson['features']:\n",
    "    fips = feature['id']\n",
    "    coords = feature['geometry']['coordinates']\n",
    "    \n",
    "    # Handle both Polygon and MultiPolygon\n",
    "    try:\n",
    "        if feature['geometry']['type'] == 'Polygon':\n",
    "            all_coords = coords[0]\n",
    "        else:\n",
    "            all_coords = coords[0][0]\n",
    "            \n",
    "        lats = [c[1] for c in all_coords]\n",
    "        lons = [c[0] for c in all_coords]\n",
    "        \n",
    "        centroids.append({\n",
    "            'fips_code': fips.zfill(5),\n",
    "            'lat'      : np.mean(lats),\n",
    "            'lon'      : np.mean(lons)\n",
    "        })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "centroids_df = pd.DataFrame(centroids)\n",
    "print(f\"County centroids loaded: {len(centroids_df)}\")\n",
    "centroids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe25377-340a-407e-8a46-ec3f0f396251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counties in MySQL:        3324\n",
      "Counties with GeoJSON:    3221\n",
      "Counties missing GeoJSON: 103\n",
      "\n",
      "Missing counties:\n",
      "\n",
      "fips_code                   county_name state_name\n",
      "    02158          Kusilvak Census Area         AK\n",
      "    16000                       Unknown         AK\n",
      "    06000                       Unknown         AL\n",
      "    04000                       Unknown         AR\n",
      "    41000                       Unknown         AR\n",
      "    60010              Eastern District         AS\n",
      "    60020               Manu'a District         AS\n",
      "    60030                   Rose Island         AS\n",
      "    60040                 Swains Island         AS\n",
      "    60050              Western District         AS\n",
      "    30000                       Unknown         AZ\n",
      "    53000                       Unknown         AZ\n",
      "    08000                       Unknown         CO\n",
      "    40000                       Unknown         CT\n",
      "    35000                       Unknown         GA\n",
      "    66010                          Guam         GU\n",
      "    46000                       Unknown         IL\n",
      "    12000                       Unknown         KS\n",
      "    27000                       Unknown         KY\n",
      "    60000                       Unknown         KY\n",
      "    09000                       Unknown         MI\n",
      "    01000                       Unknown         MO\n",
      "    28000                       Unknown         MO\n",
      "    38000                       Unknown         MO\n",
      "    44000                       Unknown         MO\n",
      "    69085 Northern Islands Municipality         MP\n",
      "    69100             Rota Municipality         MP\n",
      "    69110           Saipan Municipality         MP\n",
      "    69120           Tinian Municipality         MP\n",
      "    02000                       Unknown         NC\n",
      "    02201                       Unknown         NC\n",
      "    49000                       Unknown         ND\n",
      "    19000                       Unknown         NM\n",
      "    02280                       Unknown         NV\n",
      "    56000                       Unknown         NY\n",
      "    23000                       Unknown         OH\n",
      "    31000                       Unknown         OH\n",
      "    32000                       Unknown         OH\n",
      "    55000                       Unknown         OH\n",
      "    05000                       Unknown         OK\n",
      "    18000                       Unknown         PA\n",
      "    11000                       Unknown         PR\n",
      "    15000                       Unknown         PR\n",
      "    21000                       Unknown         PR\n",
      "    29000                       Unknown         PR\n",
      "    39000                       Unknown         PR\n",
      "    42000                       Unknown         PR\n",
      "    45000                       Unknown         PR\n",
      "    47000                       Unknown         PR\n",
      "    50000                       Unknown         PR\n",
      "    54000                       Unknown         PR\n",
      "    64000                       Unknown         PR\n",
      "    64002                       Unknown         PR\n",
      "    64005                       Unknown         PR\n",
      "    64040                       Unknown         PR\n",
      "    64060                       Unknown         PR\n",
      "    66000                       Unknown         PR\n",
      "    68000                       Unknown         PR\n",
      "    68010                       Unknown         PR\n",
      "    68030                       Unknown         PR\n",
      "    68040                       Unknown         PR\n",
      "    68070                       Unknown         PR\n",
      "    68080                       Unknown         PR\n",
      "    68090                       Unknown         PR\n",
      "    68110                       Unknown         PR\n",
      "    68120                       Unknown         PR\n",
      "    68140                       Unknown         PR\n",
      "    68150                       Unknown         PR\n",
      "    68160                       Unknown         PR\n",
      "    68170                       Unknown         PR\n",
      "    68180                       Unknown         PR\n",
      "    68190                       Unknown         PR\n",
      "    68300                       Unknown         PR\n",
      "    68310                       Unknown         PR\n",
      "    68320                       Unknown         PR\n",
      "    68330                       Unknown         PR\n",
      "    68340                       Unknown         PR\n",
      "    68390                       Unknown         PR\n",
      "    68400                       Unknown         PR\n",
      "    68410                       Unknown         PR\n",
      "    68420                       Unknown         PR\n",
      "    68430                       Unknown         PR\n",
      "    70000                       Unknown         PR\n",
      "    72000                       Unknown         PR\n",
      "    78000                       Unknown         PR\n",
      "    36000                       Unknown         PW\n",
      "    51000                       Unknown         SD\n",
      "    69010                       Unknown         TN\n",
      "    13000                       Unknown         TX\n",
      "    20000                       Unknown         TX\n",
      "    26000                       Unknown         VA\n",
      "    78010              St. Croix Island         VI\n",
      "    78020               St. John Island         VI\n",
      "    78030             St. Thomas Island         VI\n",
      "    10000                       Unknown         VI\n",
      "    17000                       Unknown         VI\n",
      "    24000                       Unknown         VI\n",
      "    33000                       Unknown         VI\n",
      "    25000                       Unknown         VT\n",
      "    34000                       Unknown         WI\n",
      "    37000                       Unknown         WI\n",
      "    22000                       Unknown         WY\n",
      "    48000                       Unknown         WY\n"
     ]
    }
   ],
   "source": [
    "# Find counties in MySQL that have no GeoJSON centroid\n",
    "mysql_fips  = set(counties['fips_code'])\n",
    "geojson_fips = set(centroids_df['fips_code'])\n",
    "\n",
    "missing_fips = mysql_fips - geojson_fips\n",
    "\n",
    "# Pull full county info for missing ones\n",
    "missing_counties = pd.read_sql(\n",
    "    f\"\"\"\n",
    "    SELECT fips_code, county_name, state_name \n",
    "    FROM counties \n",
    "    WHERE fips_code IN ({','.join([f\"'{f}'\" for f in missing_fips])})\n",
    "    ORDER BY state_name, county_name\n",
    "    \"\"\",\n",
    "    engine\n",
    ")\n",
    "\n",
    "print(f\"Counties in MySQL:        {len(mysql_fips)}\")\n",
    "print(f\"Counties with GeoJSON:    {len(geojson_fips)}\")\n",
    "print(f\"Counties missing GeoJSON: {len(missing_fips)}\")\n",
    "print(f\"\\nMissing counties:\\n\")\n",
    "print(missing_counties.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fabc6f2-e210-42eb-9eee-256dd188d384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miami to New York: 1092 miles (should be ~1280)\n"
     ]
    }
   ],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate distance in miles between two lat/lon points\"\"\"\n",
    "    R = 3959  # Earth radius in miles\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "# Test it - distance from Miami to New York should be ~1280 miles\n",
    "test = haversine_distance(25.77, -80.19, 40.71, -74.00)\n",
    "print(f\"Miami to New York: {test:.0f} miles (should be ~1280)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99646195-f27c-4485-b757-fec5d0f9d6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miami Airport to JFK: 1092 miles (should be ~1,090)\n",
      "\n",
      "✅ Formula is correct - 1,090 miles is the straight line distance\n",
      "The 1,280 figure is driving distance which follows roads, not a straight line\n"
     ]
    }
   ],
   "source": [
    "# Test with more precise coordinates\n",
    "# Miami International Airport vs JFK Airport\n",
    "test1 = haversine_distance(25.7959, -80.2870, 40.6413, -73.7781)\n",
    "print(f\"Miami Airport to JFK: {test1:.0f} miles (should be ~1,090)\")\n",
    "\n",
    "# The ~1280 figure is actually driving distance, not straight line!\n",
    "# Straight line (as the crow flies) Miami to NYC is ~1,090 miles\n",
    "# 1,280 is the driving distance - our formula is correct!\n",
    "print(f\"\\n✅ Formula is correct - 1,090 miles is the straight line distance\")\n",
    "print(f\"The 1,280 figure is driving distance which follows roads, not a straight line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e8dbab-15fb-4c15-8e30-eba5527a8e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0 of 54749...\n",
      "Processing row 5000 of 54749...\n",
      "Processing row 10000 of 54749...\n",
      "Processing row 15000 of 54749...\n",
      "Processing row 20000 of 54749...\n",
      "Processing row 25000 of 54749...\n",
      "Processing row 30000 of 54749...\n",
      "Processing row 35000 of 54749...\n",
      "Processing row 40000 of 54749...\n",
      "Processing row 45000 of 54749...\n",
      "Processing row 50000 of 54749...\n",
      "\n",
      "✅ Done!\n",
      "Total county-storm hits: 504398\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_code</th>\n",
       "      <th>storm_id</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48469</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>80</td>\n",
       "      <td>140.535922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48039</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>80</td>\n",
       "      <td>93.421665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48481</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>80</td>\n",
       "      <td>121.732291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48089</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>80</td>\n",
       "      <td>148.995514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48157</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>80</td>\n",
       "      <td>119.344981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48201</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>80</td>\n",
       "      <td>119.585093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48239</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>80</td>\n",
       "      <td>124.010988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48391</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>80</td>\n",
       "      <td>133.733776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48007</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>80</td>\n",
       "      <td>130.185358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48057</td>\n",
       "      <td>AL011851</td>\n",
       "      <td>80</td>\n",
       "      <td>115.749630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fips_code  storm_id  wind_speed    distance\n",
       "0     48469  AL011851          80  140.535922\n",
       "1     48039  AL011851          80   93.421665\n",
       "2     48481  AL011851          80  121.732291\n",
       "3     48089  AL011851          80  148.995514\n",
       "4     48157  AL011851          80  119.344981\n",
       "5     48201  AL011851          80  119.585093\n",
       "6     48239  AL011851          80  124.010988\n",
       "7     48391  AL011851          80  133.733776\n",
       "8     48007  AL011851          80  130.185358\n",
       "9     48057  AL011851          80  115.749630"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "RADIUS_MILES = 150\n",
    "\n",
    "# Convert everything to numpy arrays for fast vectorized math\n",
    "county_lats = centroids_df['lat'].values\n",
    "county_lons = centroids_df['lon'].values\n",
    "county_fips = centroids_df['fips_code'].values\n",
    "\n",
    "county_hits = []\n",
    "\n",
    "total = len(hurdat)\n",
    "\n",
    "for i, storm_row in hurdat.iterrows():\n",
    "    if i % 5000 == 0:\n",
    "        print(f\"Processing row {i} of {total}...\")\n",
    "\n",
    "    # Vectorized haversine - calculates distance to ALL counties at once\n",
    "    R = 3959\n",
    "    lat1 = np.radians(storm_row['latitude'])\n",
    "    lon1 = np.radians(storm_row['longitude'])\n",
    "    lat2 = np.radians(county_lats)\n",
    "    lon2 = np.radians(county_lons)\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    distances = 2 * R * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "\n",
    "    # Find counties within radius\n",
    "    nearby = np.where(distances <= RADIUS_MILES)[0]\n",
    "\n",
    "    for idx in nearby:\n",
    "        county_hits.append({\n",
    "            'fips_code' : county_fips[idx],\n",
    "            'storm_id'  : storm_row['storm_id'],\n",
    "            'wind_speed': storm_row['wind_speed'],\n",
    "            'distance'  : distances[idx]\n",
    "        })\n",
    "\n",
    "hits_df = pd.DataFrame(county_hits)\n",
    "print(f\"\\n✅ Done!\")\n",
    "print(f\"Total county-storm hits: {len(hits_df)}\")\n",
    "hits_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89fb4ae3-180b-4b19-8561-d15d1990c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counties with hurricane susceptibility: 2557\n",
      "\n",
      "Top 10 most susceptible counties:\n",
      "fips_code  storm_count  avg_wind_speed  susceptibility_score\n",
      "    37055          285       54.724654              1.000000\n",
      "    37031          281       53.122748              0.957049\n",
      "    37095          276       53.034568              0.938434\n",
      "    37137          274       52.377404              0.920064\n",
      "    37129          269       51.461625              0.887436\n",
      "    37177          263       52.495845              0.885076\n",
      "    37133          262       51.377962              0.862903\n",
      "    37141          260       51.446321              0.857447\n",
      "    37019          263       50.572738              0.852605\n",
      "    37049          251       51.371501              0.826516\n"
     ]
    }
   ],
   "source": [
    "# Aggregate hits by county\n",
    "susceptibility = hits_df.groupby('fips_code').agg(\n",
    "    storm_count    = ('storm_id',   'nunique'),  # unique storms that hit\n",
    "    avg_wind_speed = ('wind_speed', 'mean')      # average wind speed\n",
    ").reset_index()\n",
    "\n",
    "# Normalize to 0-1 scale\n",
    "susceptibility['susceptibility_score'] = (\n",
    "    susceptibility['storm_count'] * susceptibility['avg_wind_speed']\n",
    ")\n",
    "\n",
    "# Normalize to 0-1\n",
    "min_val = susceptibility['susceptibility_score'].min()\n",
    "max_val = susceptibility['susceptibility_score'].max()\n",
    "\n",
    "susceptibility['susceptibility_score'] = (\n",
    "    (susceptibility['susceptibility_score'] - min_val) / (max_val - min_val)\n",
    ")\n",
    "\n",
    "print(f\"Counties with hurricane susceptibility: {len(susceptibility)}\")\n",
    "print(f\"\\nTop 10 most susceptible counties:\")\n",
    "print(\n",
    "    susceptibility.sort_values('susceptibility_score', ascending=False)\n",
    "    .head(10)\n",
    "    .to_string(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc71515-e038-46ef-9db3-cb9a92a6e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fips_code         county_name state_name  storm_count  susceptibility_score\n",
      "    37055         Dare County         NC          285              1.000000\n",
      "    37031     Carteret County         NC          281              0.957049\n",
      "    37095         Hyde County         NC          276              0.938434\n",
      "    37137      Pamlico County         NC          274              0.920064\n",
      "    37129  New Hanover County         NC          269              0.887436\n",
      "    37177      Tyrrell County         NC          263              0.885076\n",
      "    37133       Onslow County         NC          262              0.862903\n",
      "    37141       Pender County         NC          260              0.857447\n",
      "    37019    Brunswick County         NC          263              0.852605\n",
      "    37049       Craven County         NC          251              0.826516\n",
      "    12085       Martin County         FL          231              0.822577\n",
      "    37013     Beaufort County         NC          249              0.820244\n",
      "    12111    St. Lucie County         FL          233              0.811019\n",
      "    45019   Charleston County         SC          252              0.809825\n",
      "    37187   Washington County         NC          240              0.794970\n",
      "    37053    Currituck County         NC          240              0.792637\n",
      "    37103        Jones County         NC          242              0.789462\n",
      "    45051        Horry County         SC          245              0.789138\n",
      "    12061 Indian River County         FL          233              0.786691\n",
      "    37047     Columbus County         NC          246              0.786147\n"
     ]
    }
   ],
   "source": [
    "# Pull county names for top 20 to verify they make geographic sense\n",
    "top20 = susceptibility.sort_values('susceptibility_score', ascending=False).head(20)\n",
    "\n",
    "top20_named = top20.merge(\n",
    "    pd.read_sql(\"SELECT fips_code, county_name, state_name FROM counties\", engine),\n",
    "    on='fips_code',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(top20_named[['fips_code','county_name','state_name','storm_count','susceptibility_score']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a609a4a0-490a-4a84-990f-2c8200d41207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counties to load: 2557\n",
      "✅ 2557 county susceptibility scores loaded into MySQL!\n"
     ]
    }
   ],
   "source": [
    "# Only keep counties that exist in our counties table\n",
    "valid_fips = pd.read_sql(\"SELECT fips_code FROM counties\", engine)['fips_code'].tolist()\n",
    "\n",
    "susceptibility_clean = susceptibility[susceptibility['fips_code'].isin(valid_fips)]\n",
    "\n",
    "print(f\"Counties to load: {len(susceptibility_clean)}\")\n",
    "\n",
    "susceptibility_clean.to_sql(\n",
    "    name='hurricane_susceptibility',\n",
    "    con=engine,\n",
    "    if_exists='append',\n",
    "    index=False,\n",
    "    chunksize=500\n",
    ")\n",
    "\n",
    "print(f\"✅ {len(susceptibility_clean)} county susceptibility scores loaded into MySQL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58e0802b-0367-4c72-9197-526b739c9984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total_counties  avg_score  max_score  high_risk_counties\n",
      "           2557     0.1789        1.0               284.0\n"
     ]
    }
   ],
   "source": [
    "check = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*)                    as total_counties,\n",
    "        ROUND(AVG(susceptibility_score), 4)  as avg_score,\n",
    "        ROUND(MAX(susceptibility_score), 4)  as max_score,\n",
    "        SUM(CASE WHEN susceptibility_score > 0.5 THEN 1 ELSE 0 END) as high_risk_counties\n",
    "    FROM hurricane_susceptibility\n",
    "\"\"\", engine)\n",
    "\n",
    "print(check.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d271c5a9-73fc-4ab9-acda-1ad644ced90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Storm Risk (venv)",
   "language": "python",
   "name": "storm_risk_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
